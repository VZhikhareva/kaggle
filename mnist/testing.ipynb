{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/222/large_data/kaggle/mnist/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'answers.txt') as f:\n",
    "    lines = [line.rstrip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answers = [int(float(lines[i])) for i in range(len(lines))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'answers_fin.txt', 'w+') as f:\n",
    "    for item in answers:\n",
    "        f.write(str(item) + '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('C:/222/large_data/kaggle/mnist/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows2array(data):\n",
    "    data = np.array(data).reshape(-1, 28, 28)\n",
    "    return data.reshape(-1, 28, 28, 1)\n",
    "#     return np.array(data).reshape(-1, 28, 28, 1)\n",
    "test_data = rows2array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/222/large_data/kaggle/mnist/my_model\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument array([[[[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        ...,\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]]],\n\n\n       [[[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        ...,\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]]],\n\n\n       [[[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        ...,\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]]],\n\n\n       ...,\n\n\n       [[[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        ...,\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]]],\n\n\n       [[[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        ...,\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]]],\n\n\n       [[[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        ...,\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]]]], dtype=int64) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    299\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 300\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    301\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3477\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3478\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3566\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" % (type(obj).__name__,\n\u001b[1;32m-> 3567\u001b[1;33m                                                            types_str))\n\u001b[0m\u001b[0;32m   3568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can not convert a ndarray into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-d09220130248>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1137\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \"\"\"\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    261\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0m_is_attrs_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_AttrsFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     self._mappers = [\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m     ]\n\u001b[0;32m    405\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     self._mappers = [\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m     ]\n\u001b[0;32m    405\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    302\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[0;32m    303\u001b[0m                         \u001b[1;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[0;32m    305\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument array([[[[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        ...,\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]]],\n\n\n       [[[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        ...,\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]]],\n\n\n       [[[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        ...,\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]]],\n\n\n       ...,\n\n\n       [[[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        ...,\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]]],\n\n\n       [[[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        ...,\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]]],\n\n\n       [[[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        ...,\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]]]], dtype=int64) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    graph = tf.get_default_graph()\n",
    "    saver.restore(sess, path + 'my_model')\n",
    "    x = graph.get_tensor_by_name(\"x:0\")\n",
    "    feed_dict = {x: test_data}\n",
    "    sess.run(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/222/large_data/kaggle/mnist/my_model\n",
      "(?, 28, 28, 1)\n",
      "(28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()    \n",
    "#First let's load meta graph and restore weights\n",
    "saver = tf.train.import_meta_graph(path + 'my_model.meta')\n",
    "saver.restore(sess,tf.train.latest_checkpoint(path))\n",
    "graph = tf.get_default_graph()\n",
    "x = graph.get_tensor_by_name(\"x:0\")\n",
    "print(x.shape)\n",
    "feed_dict = {x: test_data}\n",
    "print(np.shape(feed_dict[x]))\n",
    "prediction = graph.get_tensor_by_name('pred:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholders = [op for op in graph.get_operations() if op.type == \"Placeholder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.get_tensor_by_name(\"x_31:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.run(prediction, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
